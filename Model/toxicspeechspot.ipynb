{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Importing Modules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h2o\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os.path\n",
    "\n",
    "###Removing current instances of H2o and initialising H2o\n",
    "\n",
    "h2o.init(ip='localhost', nthreads=10,\n",
    "                     min_mem_size='1G', max_mem_size='8G')\n",
    "h2o.remove_all()\n",
    "\n",
    "###Importing H2o\n",
    "\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.model.metrics_base import H2OBinomialModelMetrics \n",
    "from h2o.grid.metrics import H2OBinomialGridSearch\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.model import H2OBinomialModel\n",
    "from h2o.model.model_base import ModelBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###loading raw data\n",
    "#training\n",
    "\n",
    "training_data = h2o.import_file(\"/home/will/Computerscience/Machinelearning/Projects/Toxicspeechspot/Programdata/train_tagged.csv\")\n",
    "\n",
    "print(\"Training CSV file imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###Splitting training data into training, validation and testing \n",
    "\n",
    "train, valid = training_data.split_frame([.7])\n",
    "\n",
    "print(\"Frame split correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "testing_data = h2o.import_file(\"/home/will/Computerscience/Machinelearning/Projects/Toxicspeechspot/Programdata/test_tagged.csv\")\n",
    "\n",
    "print(\"Testing CSV file imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Defining predictor and response\n",
    "#train[\"comment_text\",\"tagged_length\"] = train[\"comment_text\",\"tagged_length\"].asfactor()\n",
    "train[\"toxic\"] = train[\"toxic\"].asfactor()\n",
    "predictor = [\"comment_text\",\"tagged_length\"]\n",
    "response = \"toxic\"\n",
    "\n",
    "print(\"Predictor and repsonese assigned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###grid_search parameters\n",
    "\n",
    "criteria = {'strategy': 'RandomDiscrete',\n",
    "           'max_models':1000,\n",
    "           'seed': 1234\n",
    "           }\n",
    "\n",
    "###Defining hyper params\n",
    "\n",
    "sample_rate_hp = [i * 0.1 for i in range(1, 9)]\n",
    "ntrees_hp = 10 #[100,500,1000, 2000, 3000, 4000]\n",
    "folds = 5\n",
    "\n",
    "hyperparams= {\"sample_rate\": sample_rate_hp , \"ntrees\" : ntrees_hp}\n",
    "\n",
    "print(\"Hyper parameters and grid search parameters assigned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define the grid search\n",
    "\n",
    "toxic_rdf_grid = H2OGridSearch(model=H2ORandomForestEstimator,\n",
    "                              grid_id='toxic_rdf_grid_id',\n",
    "                              hyper_params=hyperparams,\n",
    "                              search_criteria=criteria)\n",
    "\n",
    "print(\"Grid search defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###Running the grid search\n",
    "\n",
    "toxic_rdf_grid.train(predictor,\n",
    "                    response,\n",
    "                    training_frame=train,\n",
    "                    validation_frame=valid)#,\n",
    "                     #nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###model performance sorted by logloss\n",
    "model_perf = toxic_rdf_grid.sorted_metric_table() \n",
    "\n",
    "written = False\n",
    "i = 0\n",
    "\n",
    "while written == False:\n",
    "    if os.path.exists(\"/home/will/Computerscience/Machinelearning/Projects/Toxicspeechspot/Modelperformance/model_performance{0}.csv\".format(i)) == True:\n",
    "        i = i + 1\n",
    "    else:\n",
    "        model_perf.to_csv(\"/home/will/Computerscience/Machinelearning/Projects/Toxicspeechspot/Modelperformance/model_performance{0}.csv\".format(i))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
